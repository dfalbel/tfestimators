#' @param <%= name %>
#'   The activation function to apply to each layer. This can either be an
#'   actual activation function (e.g. \code{tf$nn$relu}), or the name of an
#'   activation function (e.g. \code{"relu"}). Defaults to the
#'   \code{"<%= default %>"} activation function. See
#'   \url{https://www.tensorflow.org/api_guides/python/nn#Activation_Functions}
#'   for documentation related to the set of activation functions available
#'   in TensorFlow.
